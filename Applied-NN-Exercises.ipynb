{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FSugZgHdkajY"
      },
      "source": [
        "# Applied Neural Networks - Exercises\n",
        "\n",
        "**NOTICE:**\n",
        "1. You are allowed to work in groups of up to three people but **have to document** your group's\\\n",
        " members in the top cell of your notebook.\n",
        "2. **Comment your code**, explain what you do (refer to the slides). It will help you understand the topics\\\n",
        " and help me understand your thinking progress. Quality of comments will be graded.\n",
        "3. **Discuss** and analyze your results, **write-down your learnings**. These exercises are no programming\\\n",
        " exercises it is about learning and getting a touch for these methods. Such questions might be asked in the\\\n",
        " final exams.\n",
        " 4. Feel free to **experiment** with these methods. Change parameters think about improvements, write down\\\n",
        " what you learned. This is not only about collecting points for the final grade, it is about understanding\\\n",
        "  the methods."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sFReMDJgkajZ"
      },
      "source": [
        "### Exercise 1 - Data Normalization and Standardization\n",
        "\n",
        "\n",
        "**Summary:** In this exercise you will implement the min-max normalization and standardization and compare it to\\\n",
        "sklearn's implementation. It is important to remember, that we always normalize or standardize for all samples\\\n",
        " over a single feature dimension.\n",
        "\n",
        "\n",
        "**Provided Code:** In the cell below I have provided you with a sample code to initialize some dummy data.\\\n",
        "The parameter ```n_samples``` defines the number of samples we have in the training set (the number of $x_i$)\\\n",
        "while ```n_features``` defines the number of dimensions of each sample feature vector.\n",
        "\n",
        "\n",
        "**Your Tasks in this exercise:**\n",
        "1. Implement the MinMax Normalization and Standardization.\n",
        "2. Use the ```MinMaxScaler``` and ```StandardScaler``` from sklearn to verify your results.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "llbzqEfTkajZ"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import make_regression\n",
        "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
        "import numpy as np\n",
        "\n",
        "x,y = make_regression(n_samples=10, n_features=5)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# min aller features\n",
        "x_min = np.min(x, axis=0)\n",
        "\n",
        "# max aller features\n",
        "x_max = np.max(x, axis=0)\n",
        "\n",
        "# min-max scaling fuer alle features\n",
        "x_minmax = (x - x_min) / (x_max - x_min)\n",
        "\n",
        "print(\"Min-Max eigene Implementierung:\\n\", x_minmax)\n",
        "# Man sieht hier sehr gut, dass es fuer jedes Feature ein Wert mit 1 und einen Wert mit 0 gibt (die jeweiligen Min und Max-Werte, koennten auch mehrere sein, wenn min/max oefter vorkommt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nsmap-tGLGkq",
        "outputId": "e5c104f8-7427-4a11-e389-fb50ab5928c0"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Min-Max eigene Implementierung:\n",
            " [[0.40476159 0.         0.17716244 0.27016344 0.77448957]\n",
            " [0.84425891 0.79578881 0.         0.70276872 0.3206469 ]\n",
            " [0.59055143 0.0340245  0.82246469 0.         0.38462419]\n",
            " [0.22575837 0.74033427 1.         0.61025864 0.77448137]\n",
            " [0.9039843  0.27394465 0.42086525 0.28601121 1.        ]\n",
            " [0.28053095 0.78636198 0.61146714 0.68207098 0.99822039]\n",
            " [0.69682372 0.27853834 0.1201718  0.72880628 0.28458586]\n",
            " [0.         0.19147452 0.55615255 0.6246069  0.87092676]\n",
            " [1.         1.         0.62533191 0.70996065 0.        ]\n",
            " [0.59888451 0.68412728 0.36641176 1.         0.41290151]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# mittelwert aller features\n",
        "x_mean = np.mean(x, axis=0)\n",
        "# standardabweichung der features\n",
        "x_std = np.std(x, axis=0)\n",
        "\n",
        "# standardisieren fuer alle features\n",
        "x_standard = (x - x_mean) / x_std\n",
        "\n",
        "print(\"Standardisierung eigene Implementierung:\\n\", x_standard)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W4v39YJeLoQk",
        "outputId": "fd95d8e5-4669-4ee9-f85c-ea5a02d1c9a2"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Standardisierung eigene Implementierung:\n",
            " [[ 0.11799284 -1.12805277  0.02974996  0.13646306  0.63115847]\n",
            " [-0.92152661 -0.95868573 -0.35009711 -0.69347962  0.54993941]\n",
            " [ 1.15160204  2.55352086 -0.53507049 -0.74207601  0.11676113]\n",
            " [ 1.34497229 -0.18915711  1.52785078  0.39925133 -0.76008397]\n",
            " [-0.98295316  0.49297021  0.39989602  0.91010791 -0.0182514 ]\n",
            " [-1.2115191  -0.28801916 -1.59232798 -0.57159153  0.45440062]\n",
            " [ 1.29353073 -0.74586075  1.18133462  1.14781109 -0.27408406]\n",
            " [-0.11641085  0.00612881 -0.98863151  1.8065881   0.22385202]\n",
            " [ 0.57119461  0.538934   -0.86930624 -1.50535665 -2.45548554]\n",
            " [-1.24688279 -0.28177836  1.19660195 -0.88771766  1.53179332]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# minmax-scaler aus sklearn erstellen\n",
        "scaler_minmax = MinMaxScaler()\n",
        "# scaler fitten (min-max der features berechnen) und transformen (das wirkliche anpassen jedes wertes an das gefittete)\n",
        "x_minmax_sklearn = scaler_minmax.fit_transform(x)\n",
        "\n",
        "print(\"Sklearn MinMax-Scaler:\\n\", x_minmax_sklearn)\n",
        "print(\"Differenz: \", np.sum(x_minmax - x_minmax_sklearn))\n",
        "\n",
        "print(\"Verglichen mit der eigenen Implementierung, sieht man, dass unsere Implementierung ebenfalls richtig sein sollte. Differenz ist sehr gering.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6mSD-pB3L07-",
        "outputId": "4d2c4100-9da9-48da-c306-4849e3d4cdc9"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sklearn MinMax-Scaler:\n",
            " [[0.40476159 0.         0.17716244 0.27016344 0.77448957]\n",
            " [0.84425891 0.79578881 0.         0.70276872 0.3206469 ]\n",
            " [0.59055143 0.0340245  0.82246469 0.         0.38462419]\n",
            " [0.22575837 0.74033427 1.         0.61025864 0.77448137]\n",
            " [0.9039843  0.27394465 0.42086525 0.28601121 1.        ]\n",
            " [0.28053095 0.78636198 0.61146714 0.68207098 0.99822039]\n",
            " [0.69682372 0.27853834 0.1201718  0.72880628 0.28458586]\n",
            " [0.         0.19147452 0.55615255 0.6246069  0.87092676]\n",
            " [1.         1.         0.62533191 0.70996065 0.        ]\n",
            " [0.59888451 0.68412728 0.36641176 1.         0.41290151]]\n",
            "Differenz:  2.0816681711721685e-16\n",
            "Verglichen mit der eigenen Implementierung, sieht man, dass unsere Implementierung ebenfalls richtig sein sollte. Differenz ist sehr gering.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# standard-scaler aus sklearn erstellen\n",
        "scaler_standard = StandardScaler()\n",
        "# scaler fitten (mean und std der features berechnen) und transformen (das wirkliche anpassen jedes wertes an das gefittete)\n",
        "x_standard_sklearn = scaler_standard.fit_transform(x)\n",
        "\n",
        "print(\"Sklearn Standard-Scaler:\\n\", x_standard_sklearn)\n",
        "print(\"Differenz: \", np.sum(x_standard - x_standard_sklearn))\n",
        "\n",
        "print(\"Verglichen mit der eigenen Implementierung, sieht man, dass unsere Implementierung ebenfalls richtig sein sollte. Differenz ist 0.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q853zJUxL8xw",
        "outputId": "5f001058-e621-466f-bb59-498f3322f5b2"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sklearn Standard-Scaler:\n",
            " [[ 0.11799284 -1.12805277  0.02974996  0.13646306  0.63115847]\n",
            " [-0.92152661 -0.95868573 -0.35009711 -0.69347962  0.54993941]\n",
            " [ 1.15160204  2.55352086 -0.53507049 -0.74207601  0.11676113]\n",
            " [ 1.34497229 -0.18915711  1.52785078  0.39925133 -0.76008397]\n",
            " [-0.98295316  0.49297021  0.39989602  0.91010791 -0.0182514 ]\n",
            " [-1.2115191  -0.28801916 -1.59232798 -0.57159153  0.45440062]\n",
            " [ 1.29353073 -0.74586075  1.18133462  1.14781109 -0.27408406]\n",
            " [-0.11641085  0.00612881 -0.98863151  1.8065881   0.22385202]\n",
            " [ 0.57119461  0.538934   -0.86930624 -1.50535665 -2.45548554]\n",
            " [-1.24688279 -0.28177836  1.19660195 -0.88771766  1.53179332]]\n",
            "Differenz:  0.0\n",
            "Verglichen mit der eigenen Implementierung, sieht man, dass unsere Implementierung ebenfalls richtig sein sollte. Differenz ist 0.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f8klM070kaja"
      },
      "source": [
        "### Exercise 2 - Softmax\n",
        "\n",
        "**Summary:** In this exercise you will implement the softmax activation using the naive and numerically\\\n",
        "more stable log-sum variation.\n",
        "\n",
        "\n",
        "**Provided Code:** In the cell below there is some sample code that generates sample inputs.\n",
        "\n",
        "\n",
        "**Your Tasks in this exercise:**\n",
        "1. Implement the softmax function using the naive approach.\n",
        "2. Implement the softmax function using the log-sum trick.\n",
        "3. Compare your two implementations for numerical stability\\\n",
        "(experiment with different values of std) and verify\n",
        "your results using ```tf.nn.softmax```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "cva3EHhikaja"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "mu = 0\n",
        "std = 10\n",
        "xi = mu + std * np.random.randn(10)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# naiver ansatz\n",
        "def naive_softmax(x):\n",
        "  # (e hoch xi) fuer alle xi berechnen\n",
        "  exp_x = np.exp(x)\n",
        "  # diese wert jeweils durch die summe von allen e hoch xi rechnen\n",
        "  return exp_x / np.sum(exp_x)\n",
        "\n",
        "naive_softmax_values = naive_softmax(xi)\n",
        "\n",
        "print(\"Verteilung: \", naive_softmax_values)\n",
        "print(\"Summe der Verteilung: \", np.sum(naive_softmax_values))\n",
        "print(\"Die Summe der Werte ergibt annaehernd 1 was richtig erscheint.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Gy5u41tM941",
        "outputId": "008519e4-1100-4973-cfbf-14b1724695fa"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Verteilung:  [2.86706311e-11 4.77843111e-11 4.65646508e-08 7.24541737e-14\n",
            " 2.33637639e-10 4.11395992e-09 4.44796082e-10 2.76394350e-16\n",
            " 9.99999948e-01 2.49745322e-10]\n",
            "Summe der Verteilung:  1.0\n",
            "Die Summe der Werte ergibt annaehernd 1 was richtig erscheint.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def softmax_logsum(x):\n",
        "  # max xi als c speichern\n",
        "  c = np.max(x)\n",
        "  # (e hoch (xi - c)) fuer alle xi berechnen\n",
        "  exp_x = np.exp(x - c)\n",
        "  # denumerator (log(d))\n",
        "  ld = c + np.log(np.sum(exp_x))\n",
        "  # e hoch (xi - log(d))\n",
        "  return np.exp(x - ld)\n",
        "\n",
        "logsum_softmax_values = softmax_logsum(xi)\n",
        "\n",
        "print(\"Verteilung Logsum-Trick: \", logsum_softmax_values)\n",
        "print(\"Summe der Verteilung: \", np.sum(naive_softmax_values))\n",
        "print(\"Die Summe der Werte beim LogSum-Trick ergibt annaehernd 1 was richtig erscheint.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-sZdwaM0PskF",
        "outputId": "35e80f46-41fb-45ba-a107-989b5866a03d"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Verteilung Logsum-Trick:  [2.86706311e-11 4.77843111e-11 4.65646508e-08 7.24541737e-14\n",
            " 2.33637639e-10 4.11395992e-09 4.44796082e-10 2.76394350e-16\n",
            " 9.99999948e-01 2.49745322e-10]\n",
            "Summe der Verteilung:  1.0\n",
            "Die Summe der Werte beim LogSum-Trick ergibt annaehernd 1 was richtig erscheint.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Naive vs LogSum-Trick: \", np.sum(naive_softmax_values - logsum_softmax_values))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eF2gZZ58RrN7",
        "outputId": "d3453b71-6db5-4060-9574-71706b6090ab"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Naive vs LogSum-Trick:  1.1102227073898509e-16\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "xi2 = mu + 1000 * np.random.randn(10)\n",
        "\n",
        "ns = naive_softmax(xi2)\n",
        "print(\"Fuer groessere Werte bekommen wir einen Overflow-Warning bei der naiven Variante: \", ns)\n",
        "\n",
        "ls = softmax_logsum(xi2)\n",
        "print(\"Hingegen kann die logsum-variante immernoch Werte berechnen: \", ls)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RNTdXZ57UVYz",
        "outputId": "16dc4a9f-bf5b-4a74-82c9-e15452b1e79c"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fuer groessere Werte bekommen wir einen Overflow-Warning bei der naiven Variante:  [ 0.  0.  0. nan  0.  0.  0.  0.  0. nan]\n",
            "Hingegen kann die logsum-variante immernoch Werte berechnen:  [0.00000000e+000 0.00000000e+000 0.00000000e+000 1.78939304e-313\n",
            " 0.00000000e+000 0.00000000e+000 0.00000000e+000 0.00000000e+000\n",
            " 0.00000000e+000 1.00000000e+000]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-6-e99606a99de6>:4: RuntimeWarning: overflow encountered in exp\n",
            "  exp_x = np.exp(x)\n",
            "<ipython-input-6-e99606a99de6>:6: RuntimeWarning: invalid value encountered in divide\n",
            "  return exp_x / np.sum(exp_x)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf_softmax = tf.nn.softmax(xi).numpy()\n",
        "\n",
        "print(\"Differenz Naive-TF: \", np.sum(naive_softmax_values - tf_softmax))\n",
        "print(\"Differenz Logsum-Tf: \", np.sum(logsum_softmax_values - tf_softmax))\n",
        "\n",
        "print(\"Bringt uns sehr kleine Zahlen. Unsere Implementierungen scheinen in dem Fall nicht all zu falsch zu sein.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HXauULiMPI0r",
        "outputId": "b6c21903-f09a-4972-c13d-e8cd09dc6032"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Differenz Naive-TF:  -1.11022349298525e-16\n",
            "Differenz Logsum-Tf:  -2.220446200375101e-16\n",
            "Bringt uns sehr kleine Zahlen. Unsere Implementierungen scheinen in dem Fall nicht all zu falsch zu sein.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OJtjjh6Ekajb"
      },
      "source": [
        "### Exercise 3 - Chess Endgames\n",
        "\n",
        "**Summary:** In this exercise your task is to predict the optimal depth-of-win for white in   \n",
        "chess-endgames. In particular, we will focus on **king-rook** vs. **king** endgames. The   \n",
        "possible outcomes are either a **draw** or a **number of moves** for white to win (0 to 16).\n",
        "\n",
        "\n",
        "**Provided Code:** The code below loads the original (*unprepared*) raw dataset.   \n",
        "You will have to prepare it accordingly to be used with neural nets.\n",
        "\n",
        "The structure of each row in the dataset is:\n",
        "1. White King column (a-h)\n",
        "2. White King row (1-8)\n",
        "3. White Rook column (a-h)\n",
        "4. White Rook row (1-8)\n",
        "5. Black King column (a-h)\n",
        "6. Black King row (1-8)\n",
        "7. Optimal depth-of-win for White in 0 to 16 moves or a draw\n",
        "\n",
        "\n",
        "**Your Tasks in this exercise:**\n",
        "1. Train a neural net to predict the depth-of-win (or draw) given a board position\n",
        "    * You will have to prepare your data accordingly to make it compatible   \n",
        "    with neural nets. Think about input and output encodings, normalization or standardization.\n",
        "    * Decide how you will model this problem as either regression or classification task.\n",
        "    * Build a fully connected neural net with appropriate configuration and loss and train it.\n",
        "    * Use appropriate cross-validation for training and validation (it is enough to use two datasets)\n",
        "2. Explain in writing:\n",
        "    * How and why did you prepared the data?\n",
        "    * How did you model the problem task?\n",
        "    * What is your neural network architecture/configuration/loss?\n",
        "    * Plot your loss while training.\n",
        "    * Interpret and explain your results.\n",
        "    \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YSy3aOl4kajb",
        "outputId": "498a90c1-77bb-4cb3-f82c-f9fe266c6da9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-02-09 23:00:49--  https://github.com/shegenbart/Jupyter-Exercises/raw/main/data/chess_endgames.pickle\n",
            "Resolving github.com (github.com)... 140.82.116.4\n",
            "Connecting to github.com (github.com)|140.82.116.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/shegenbart/Jupyter-Exercises/main/data/chess_endgames.pickle [following]\n",
            "--2025-02-09 23:00:50--  https://raw.githubusercontent.com/shegenbart/Jupyter-Exercises/main/data/chess_endgames.pickle\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 6284700 (6.0M) [application/octet-stream]\n",
            "Saving to: ‘../data/chess_endgames.pickle.5’\n",
            "\n",
            "chess_endgames.pick 100%[===================>]   5.99M  --.-KB/s    in 0.06s   \n",
            "\n",
            "2025-02-09 23:00:50 (101 MB/s) - ‘../data/chess_endgames.pickle.5’ saved [6284700/6284700]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://github.com/shegenbart/Jupyter-Exercises/raw/main/data/chess_endgames.pickle -P ../data\n",
        "import pickle\n",
        "with open('../data/chess_endgames.pickle', 'rb') as fd:\n",
        "    chess_endgames = pickle.load(fd)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "h9G8NNclkajb"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Convert dataset to NumPy array\n",
        "data = np.array(chess_endgames)\n",
        "\n",
        "# Extract features (piece positions) and target variable (depth-of-win)\n",
        "X_raw = data[:, :-1]  # First 6 columns (positions)\n",
        "y_raw = data[:, -1]   # Last column (depth-of-win or draw)\n",
        "\n",
        "# Convert chess board columns (a-h) to numerical (1-8) if necessary\n",
        "# Assuming they are already numerical; otherwise, apply a mapping.\n",
        "\n",
        "column_mapping = { \"a\": 1, \"b\": 2, \"c\": 3, \"d\": 4, \"e\": 5, \"f\": 6, \"g\": 7, \"h\": 8}\n",
        "\n",
        "# Function to apply mapping\n",
        "def convert_chess_columns(board_positions):\n",
        "  for i in [0, 2, 4]:  # Columns for White King, White Rook, Black King\n",
        "      board_positions[:, i] = np.vectorize(column_mapping.get)(board_positions[:, i])\n",
        "  return board_positions.astype(float)\n",
        "\n",
        "X_raw = convert_chess_columns(X_raw)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalize board positions (scale between 0 and 1)\n",
        "scaler = MinMaxScaler()\n",
        "X = scaler.fit_transform(X_raw)\n",
        "X = X_raw\n",
        "\n",
        "# Convert target variable to one-hot encoding for classification\n",
        "y_raw = y_raw.reshape(-1, 1)  # Reshape for encoder\n",
        "encoder = OneHotEncoder(sparse_output=False)\n",
        "y = encoder.fit_transform(y_raw)\n",
        "\n",
        "# Split dataset into training (80%) and validation (20%)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Neural Network Model\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(256, activation='relu', input_shape=(X.shape[1],)),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.Dropout(0.4),\n",
        "    tf.keras.layers.Dense(128, activation='relu'),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.Dropout(0.3),\n",
        "    tf.keras.layers.Dense(64, activation='relu'),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.Dense(18, activation='softmax')\n",
        "])\n",
        "\n",
        "# Compile Model\n",
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train Model\n",
        "history = model.fit(X_train, y_train, validation_data=(X_val, y_val),\n",
        "                    epochs=50, batch_size=16, verbose=1)\n",
        "\n",
        "# Plot Training Loss\n",
        "plt.plot(history.history['loss'], label='Train Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.title('Training Loss Over Time')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "hfNWodxp1ydb",
        "outputId": "a8acafc8-139c-4747-ad93-0f7b52064dfe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 722
        }
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
            "Exception ignored in: <function _xla_gc_callback at 0x7b82536bff60>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/jax/_src/lib/__init__.py\", line 96, in _xla_gc_callback\n",
            "    def _xla_gc_callback(*args):\n",
            "    \n",
            "KeyboardInterrupt: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1403/1403\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 5ms/step - accuracy: 0.2342 - loss: 2.3729 - val_accuracy: 0.4319 - val_loss: 1.5439\n",
            "Epoch 2/50\n",
            "\u001b[1m1403/1403\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.3438 - loss: 1.7770 - val_accuracy: 0.4531 - val_loss: 1.4534\n",
            "Epoch 3/50\n",
            "\u001b[1m1403/1403\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.3645 - loss: 1.6867 - val_accuracy: 0.4569 - val_loss: 1.4150\n",
            "Epoch 4/50\n",
            "\u001b[1m1403/1403\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.3757 - loss: 1.6447 - val_accuracy: 0.4898 - val_loss: 1.3671\n",
            "Epoch 5/50\n",
            "\u001b[1m1403/1403\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.3913 - loss: 1.6207 - val_accuracy: 0.4765 - val_loss: 1.3661\n",
            "Epoch 6/50\n",
            "\u001b[1m1118/1403\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.4005 - loss: 1.6004"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-34-229595119cb9>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;31m# Train Model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m history = model.fit(X_train, y_train, validation_data=(X_val, y_val),\n\u001b[0m\u001b[1;32m     34\u001b[0m                     epochs=50, batch_size=16, verbose=1)\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    369\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mepoch_iterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    370\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 371\u001b[0;31m                     \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    372\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    373\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36mfunction\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m    217\u001b[0m                 \u001b[0miterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDistributedIterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m             ):\n\u001b[0;32m--> 219\u001b[0;31m                 \u001b[0mopt_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmulti_step_on_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    220\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mopt_outputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhas_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    831\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 833\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    834\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    876\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    877\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 878\u001b[0;31m       results = tracing_compilation.call_function(\n\u001b[0m\u001b[1;32m    879\u001b[0m           \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creation_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    880\u001b[0m       )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m   \u001b[0mbound_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m   \u001b[0mflat_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbound_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m   return function._call_flat(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    140\u001b[0m       \u001b[0mflat_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m   )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1320\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1321\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1323\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1324\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;34m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m     \u001b[0mflat_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_recording\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bound_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m             outputs = self._bound_context.call_function(\n\u001b[0m\u001b[1;32m    252\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1681\u001b[0m     \u001b[0mcancellation_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcancellation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1682\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcancellation_context\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1683\u001b[0;31m       outputs = execute.execute(\n\u001b[0m\u001b[1;32m   1684\u001b[0m           \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1685\u001b[0m           \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ],
  "metadata": {
    "celltoolbar": "Edit Metadata",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.18"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}